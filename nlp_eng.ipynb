{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "감정분석(영어).ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smartkorea/nlp/blob/main/nlp_eng.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIhzKpxQ602_",
        "outputId": "063cc28c-fd2a-4367-fa70-7c323d174d54"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EwzDlO47ido",
        "outputId": "fcdc1653-cbcf-4fc0-ea25-6ef1e7545b38"
      },
      "source": [
        "cd /content/gdrive/MyDrive/eng_sa"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/eng_sa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nvmRggV27wu",
        "outputId": "596af178-c6f8-4f79-be37-a4ff1a361f11"
      },
      "source": [
        "!pip install transformers==2.9.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.9.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 15.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (1.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (3.0.12)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 33.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 77.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.1) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.1) (1.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.1) (2020.12.5)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=4399c5bc226dda75680102e57f529199850d7871a62279981f335f2ae295a79c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd41hg5UnQ-f"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import torch\r\n",
        "from transformers import BertTokenizer\r\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\r\n",
        "from transformers import get_linear_schedule_with_warmup\r\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import time\r\n",
        "import datetime\r\n",
        "import json\r\n",
        "import re\r\n",
        "import nltk\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKDppyljnXAP",
        "outputId": "bab3f388-b216-4349-9b9c-c27a3448726d"
      },
      "source": [
        "nltk.download('stopwords')\r\n",
        "stops = set(stopwords.words('english'))\r\n",
        "stemmer = nltk.stem.SnowballStemmer('english')\r\n",
        "with open('./friends_train.json', encoding='utf-8') as json_file:\r\n",
        "    json_train = json.load(json_file)\r\n",
        "\r\n",
        "\r\n",
        "def cleaning(str):\r\n",
        "    replaceAll= str\r\n",
        "    only_english = re.sub('[^a-zA-Z]', ' ', replaceAll)\r\n",
        "    no_capitals = only_english.lower().split()\r\n",
        "    no_stops = [word for word in no_capitals if not word in stops]\r\n",
        "    stemmer_words = [stemmer.stem(word) for word in no_stops]\r\n",
        "    #return ' '.join(stemmer_words)\r\n",
        "    return ' '.join(no_capitals)\r\n",
        "\r\n",
        "i = 0\r\n",
        "train_data=[]\r\n",
        "for rows in json_train:\r\n",
        "    for row in rows:\r\n",
        "        #train_data.append([cleaning(row['utterance']), row['emotion']])\r\n",
        "        train_data.append([cleaning(row['utterance']), row['emotion']])\r\n",
        "    "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCuMJ79Xp7Si",
        "outputId": "27f67a19-5e94-4068-c6a4-7175e102038b"
      },
      "source": [
        "train_data[10:30]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['no don t i beg of you', 'fear'],\n",
              " ['all right then we ll have a definite answer for you on monday but i think i can say with some confidence you ll fit in well here',\n",
              "  'neutral'],\n",
              " ['really', 'surprise'],\n",
              " ['absolutely you can relax you did great', 'neutral'],\n",
              " ['but then who the waitress i went out with last month', 'surprise'],\n",
              " ['you know forget it', 'non-neutral'],\n",
              " ['no no no no no who who were you talking about', 'surprise'],\n",
              " ['no i i i i don t i actually don t know', 'non-neutral'],\n",
              " ['ok', 'neutral'],\n",
              " ['all right well', 'neutral'],\n",
              " ['i m gonna see if i can get a room for the night and i ll', 'non-neutral'],\n",
              " ['i ll see you later', 'non-neutral'],\n",
              " ['yeah sure', 'neutral'],\n",
              " ['hey mon', 'neutral'],\n",
              " ['hey hey hey you wanna hear something that sucks', 'neutral'],\n",
              " ['do i ever', 'joy'],\n",
              " ['chris says they re closing down the bar', 'sadness'],\n",
              " ['no way', 'surprise'],\n",
              " ['yeah apparently they re turning it into some kinda coffee place',\n",
              "  'neutral'],\n",
              " ['just coffee where are we gonna hang out now', 'non-neutral']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnI5DM-Qx22L"
      },
      "source": [
        "sentences = []\r\n",
        "for i in train_data:\r\n",
        "  sentences.append(i[0])\r\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\r\n",
        "\r\n",
        "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\r\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAFQMEua9f1s"
      },
      "source": [
        "maxlen = 0\r\n",
        "for i in sentences:\r\n",
        "  if maxlen < len(i):\r\n",
        "    maxlen = len(i)\r\n",
        "\r\n",
        "MAX_LEN = maxlen + 1\r\n",
        "#MAX_LEN = 128\r\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "\r\n",
        "attention_masks = []\r\n",
        "for seq in input_ids:\r\n",
        "    seq_mask = [float(i>0) for i in seq]\r\n",
        "    attention_masks.append(seq_mask)\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ7Kd5I39xNo"
      },
      "source": [
        "def labeltoint(str):\r\n",
        "    return {'non-neutral': 0,\r\n",
        "             'neutral': 1, \r\n",
        "             'joy': 2,\r\n",
        "             'sadness': 3,\r\n",
        "             'fear': 4,\r\n",
        "             'anger': 5,\r\n",
        "             'surprise': 6,\r\n",
        "             'disgust': 7}[str]\r\n",
        "\r\n",
        "labels = []\r\n",
        "for i in train_data:\r\n",
        "  labels.append(labeltoint(i[1]))\r\n",
        "\r\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\r\n",
        "                                                                                    labels, \r\n",
        "                                                                                    random_state=41, \r\n",
        "                                                                                    test_size=0.2)\r\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \r\n",
        "                                                       input_ids,\r\n",
        "                                                       random_state=41, \r\n",
        "                                                       test_size=0.2)\r\n",
        "\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\r\n",
        "\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\r\n",
        "train_sampler = RandomSampler(train_data)\r\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\r\n",
        "\r\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\r\n",
        "validation_sampler = SequentialSampler(validation_data)\r\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqpAKp6ReKF",
        "outputId": "70ad9cec-c4bf-4252-d71f-43cd6bf0cc87"
      },
      "source": [
        "train_data[10:20]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101, 20878, 10887,  ...,     0,     0,     0],\n",
              "         [  101, 26114, 26114,  ...,     0,     0,     0],\n",
              "         [  101,  4826,  2012,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101,  1045,  2147,  ...,     0,     0,     0],\n",
              "         [  101,  1037,  2733,  ...,     0,     0,     0],\n",
              "         [  101,  1045,  2123,  ...,     0,     0,     0]]),\n",
              " tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
              " tensor([0, 0, 1, 1, 2, 2, 2, 1, 0, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqwNX9DHl4l1",
        "outputId": "cdcf008d-6f35-4031-b938-6932282c1ccd"
      },
      "source": [
        " os.path.isdir(\"./bert_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8BUeYvK_f2q",
        "outputId": "c1bbe7f4-0945-4732-ead8-7a4a7f61e69f"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name == '/device:GPU:0':\r\n",
        "    print('Found GPU at: {}'.format(device_name))\r\n",
        "else:\r\n",
        "    raise SystemError('GPU device not found')\r\n",
        "\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "\r\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=8)\r\n",
        "#model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=8)\r\n",
        "model.cuda()\r\n",
        "\r\n",
        "optimizer = AdamW(model.parameters(),\r\n",
        "                  lr = 3e-5, # 학습률\r\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n",
        "                  ,correct_bias=False\r\n",
        "                )\r\n",
        "epochs = 5\r\n",
        "total_steps = len(train_dataloader) * epochs\r\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\r\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \r\n",
        "                                            num_warmup_steps = 0,\r\n",
        "                                            num_training_steps = total_steps)\r\n",
        "\r\n",
        "# 정확도 계산 함수\r\n",
        "def flat_accuracy(preds, labels):\r\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
        "    labels_flat = labels.flatten()\r\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n",
        "\r\n",
        "# 시간 표시 함수\r\n",
        "def format_time(elapsed):\r\n",
        "    elapsed_rounded = int(round((elapsed)))\r\n",
        "    # hh:mm:ss으로 형태 변경\r\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\r\n",
        "\r\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_TT8kd2IlWK",
        "outputId": "ba1d51f0-15af-44c1-c5a0-a16c576cf4d4"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\r\n",
        "seed_val = 41\r\n",
        "random.seed(seed_val)\r\n",
        "np.random.seed(seed_val)\r\n",
        "torch.manual_seed(seed_val)\r\n",
        "torch.cuda.manual_seed_all(seed_val)\r\n",
        "\r\n",
        "model.zero_grad()\r\n",
        "\r\n",
        "for epoch_i in range(0, epochs):\r\n",
        "    \r\n",
        "    # ========================================\r\n",
        "    #               Training\r\n",
        "    # ========================================\r\n",
        "    \r\n",
        "    print(\"\")\r\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
        "    print('Training...')\r\n",
        "\r\n",
        "    # 시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "\r\n",
        "    # 로스 초기화\r\n",
        "    total_loss = 0\r\n",
        "\r\n",
        "    # 훈련모드로 변경\r\n",
        "    model.train()\r\n",
        "        \r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for step, batch in enumerate(train_dataloader):\r\n",
        "        # 경과 정보 표시\r\n",
        "        if step % 500 == 0 and not step == 0:\r\n",
        "            elapsed = format_time(time.time() - t0)\r\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
        "\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "\r\n",
        "        # Forward 수행                \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask, \r\n",
        "                        labels=b_labels)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        loss = outputs[0]\r\n",
        "\r\n",
        "        # 총 로스 계산\r\n",
        "        total_loss += loss.item()\r\n",
        "\r\n",
        "        # Backward 수행으로 그래디언트 계산\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        # 그래디언트 클리핑\r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
        "\r\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # 스케줄러로 학습률 감소\r\n",
        "        scheduler.step()\r\n",
        "\r\n",
        "        # 그래디언트 초기화\r\n",
        "        model.zero_grad()\r\n",
        "\r\n",
        "    # 평균 로스 계산\r\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "        \r\n",
        "    # ========================================\r\n",
        "    #               Validation\r\n",
        "    # ========================================\r\n",
        "\r\n",
        "    print(\"\")\r\n",
        "    print(\"Running Validation...\")\r\n",
        "\r\n",
        "    #시작 시간 설정\r\n",
        "    t0 = time.time()\r\n",
        "    model.eval()\r\n",
        "\r\n",
        "    # 변수 초기화\r\n",
        "    eval_loss, eval_accuracy = 0, 0\r\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\r\n",
        "\r\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
        "    for batch in validation_dataloader:\r\n",
        "        # 배치를 GPU에 넣음\r\n",
        "        batch = tuple(t.to(device) for t in batch)\r\n",
        "        \r\n",
        "        # 배치에서 데이터 추출\r\n",
        "        b_input_ids, b_input_mask, b_labels = batch\r\n",
        "        \r\n",
        "        # 그래디언트 계산 안함\r\n",
        "        with torch.no_grad():     \r\n",
        "            # Forward 수행\r\n",
        "            outputs = model(b_input_ids, \r\n",
        "                            token_type_ids=None, \r\n",
        "                            attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "        # 로스 구함\r\n",
        "        logits = outputs[0]\r\n",
        "\r\n",
        "        # CPU로 데이터 이동\r\n",
        "        logits = logits.detach().cpu().numpy()\r\n",
        "        label_ids = b_labels.to('cpu').numpy()\r\n",
        "        \r\n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
        "        eval_accuracy += tmp_eval_accuracy\r\n",
        "        nb_eval_steps += 1\r\n",
        "\r\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# model 저장\r\n",
        "model.save_pretrained('./bert_model/')\r\n",
        "\r\n",
        "\r\n",
        "print(\"\")\r\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  Average training loss: 1.54\n",
            "  Training epcoh took: 0:04:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.54\n",
            "  Validation took: 0:00:22\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.28\n",
            "  Training epcoh took: 0:04:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.54\n",
            "  Validation took: 0:00:22\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 1.01\n",
            "  Training epcoh took: 0:04:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.55\n",
            "  Validation took: 0:00:22\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.76\n",
            "  Training epcoh took: 0:04:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.53\n",
            "  Validation took: 0:00:22\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:04:28\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.52\n",
            "  Validation took: 0:00:22\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkEwvjChXM2J"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained('./bert_model/', num_labels=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMmgBm-fOvqp",
        "outputId": "a5b6fc25-4541-4205-d4c6-dfb8ba5266d7"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glUVvX6d5EIH",
        "outputId": "15f38fa7-2d70-4b91-b743-dd5bc8f53797"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name == '/device:GPU:0':\r\n",
        "    print('Found GPU at: {}'.format(device_name))\r\n",
        "else:\r\n",
        "    raise SystemError('GPU device not found')\r\n",
        "\r\n",
        "if torch.cuda.is_available():    \r\n",
        "    device = torch.device(\"cuda\")\r\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\r\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\r\n",
        "else:\r\n",
        "    device = torch.device(\"cpu\")\r\n",
        "    print('No GPU available, using the CPU instead.')\r\n",
        "\r\n",
        "\r\n",
        "with open('en_data.csv', 'r', encoding='utf-8', newline='') as csvfile:\r\n",
        "  en = pd.read_csv(csvfile)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "4UavWPTM555F",
        "outputId": "1a41d526-8a6a-41e0-82ec-15ee9e85ddc7"
      },
      "source": [
        "en[10:20]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>Ross</td>\n",
              "      <td>You were trying to eat it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>If</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Come on.  Hello?  I?m sorry you have the wrong...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Julie</td>\n",
              "      <td>I was thinking of doing it a little shorter, y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Oh yeah!? Oh, I can do that.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>Julie</td>\n",
              "      <td>Really?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>Hombre Man</td>\n",
              "      <td>I'm sorry. I am such a doofus. I'm so sorry, I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>Annabelle</td>\n",
              "      <td>My god, what happened?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>Joey</td>\n",
              "      <td>These new kids, they never last.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Sooner or later, they all...stop lastin'.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  i_dialog  ...     speaker                                          utterance\n",
              "10  10         1  ...        Ross                         You were trying to eat it!\n",
              "11  11         1  ...    Chandler                                                 If\n",
              "12  12         1  ...      Monica  Come on.  Hello?  I?m sorry you have the wrong...\n",
              "13  13         2  ...       Julie  I was thinking of doing it a little shorter, y...\n",
              "14  14         2  ...      Phoebe                       Oh yeah!? Oh, I can do that.\n",
              "15  15         2  ...       Julie                                            Really?\n",
              "16  16         2  ...  Hombre Man  I'm sorry. I am such a doofus. I'm so sorry, I...\n",
              "17  17         2  ...   Annabelle                             My god, what happened?\n",
              "18  18         2  ...        Joey                   These new kids, they never last.\n",
              "19  19         2  ...        Joey          Sooner or later, they all...stop lastin'.\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMwEjEzA6muI",
        "outputId": "027187ba-5038-4da7-b3a5-092f428b334c"
      },
      "source": [
        "en['utterance']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                           Alright, whadyou do with him?\n",
              "1                                       Oh! You're awake!\n",
              "2       Then you gotta come clean with Ma! This is not...\n",
              "3                                       Yeah, but this is\n",
              "4               I don't wanna hear it! Now go to my room!\n",
              "                              ...                        \n",
              "1618                                                Nooo.\n",
              "1619                                            Hi, Kate!\n",
              "1620                                          Hi, Lauren.\n",
              "1621                                          Hi, Lauren.\n",
              "1622                                             Hi, pig!\n",
              "Name: utterance, Length: 1623, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gB1ELGA8kyC"
      },
      "source": [
        "i = 0\r\n",
        "test_data=[]\r\n",
        "for ind in en.index:\r\n",
        "  #print(cleaning(en['utterance'][ind]))\r\n",
        "  test_data.append([cleaning(en['utterance'][ind])])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgDX6NmvDJCI",
        "outputId": "d3661937-89ac-4b7f-f39a-1e82eddf8995"
      },
      "source": [
        "test_data[10:20]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['you were trying to eat it'],\n",
              " ['if'],\n",
              " ['come on hello i m sorry you have the wrong number okay i ll call you later dad i love you'],\n",
              " ['i was thinking of doing it a little shorter you know like andie mcdowell s new haircut'],\n",
              " ['oh yeah oh i can do that'],\n",
              " ['really'],\n",
              " ['i m sorry i am such a doofus i m so sorry i m so sorry'],\n",
              " ['my god what happened'],\n",
              " ['these new kids they never last'],\n",
              " ['sooner or later they all stop lastin']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7h4k9yxgJqyd",
        "outputId": "e8435bd4-003a-41ee-b6da-fc21af4a31b2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you were trying to eat it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t2Tr1sW5GiE",
        "outputId": "7f84498c-521a-4d60-d55a-a14eebd9b274"
      },
      "source": [
        "def cleaning(str):\r\n",
        "    replaceAll= str\r\n",
        "    only_english = re.sub('[^a-zA-Z]', ' ', replaceAll)\r\n",
        "    no_capitals = only_english.lower().split()\r\n",
        "    no_stops = [word for word in no_capitals if not word in stops]\r\n",
        "    stemmer_words = [stemmer.stem(word) for word in no_stops]\r\n",
        "    #return ' '.join(stemmer_words)\r\n",
        "    return ' '.join(no_capitals)\r\n",
        "\r\n",
        "i = 0\r\n",
        "test_data=[]\r\n",
        "for rows in en:\r\n",
        "    #for row in rows:\r\n",
        "        #train_data.append([cleaning(row['utterance']), row['emotion']])\r\n",
        "        #test_data.append([cleaning(row['utterance']), row['emotion']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id\n",
            "i_dialog\n",
            "i_utterance\n",
            "speaker\n",
            "utterance\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkEfI8b3KZwQ"
      },
      "source": [
        "model.cuda()\r\n",
        "\r\n",
        "def test_sentences(sentences):\r\n",
        "    model.eval()\r\n",
        "    inputs, masks = convert_input_data(sentences)\r\n",
        "\r\n",
        "    b_input_ids = inputs.to(device)\r\n",
        "    b_input_mask = masks.to(device)\r\n",
        "            \r\n",
        "    with torch.no_grad():     \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "    logits = outputs[0]\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    return logits\r\n",
        "\r\n",
        "def convert_input_data(sentences):\r\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    for seq in input_ids:\r\n",
        "        seq_mask = [float(i>0) for i in seq]\r\n",
        "        attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "    inputs = torch.tensor(input_ids)\r\n",
        "    masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "    return inputs, masks\r\n",
        "\r\n",
        "def inttolabel(idx):\r\n",
        "    return {0:'non-neutral',\r\n",
        "             1:'neutral', \r\n",
        "             2:'joy',\r\n",
        "             3:'sadness',\r\n",
        "             4:'fear',\r\n",
        "             5:'anger',\r\n",
        "             6:'surprise',\r\n",
        "             7:'disgust'}[idx]\r\n",
        "\r\n",
        "en_data = [['Id', 'Predicted']]\r\n",
        "\r\n",
        "for idx in range(len(test_data)):\r\n",
        "  sen = test_data[idx]\r\n",
        "  #sen = cleaning(sen)\r\n",
        "  #logit = test_sentences([sen])\r\n",
        "  logit = test_sentences(sen)\r\n",
        "\r\n",
        "  en_data.append([idx, inttolabel(np.argmax(logit))])\r\n",
        "\r\n",
        "dataframe = pd.DataFrame(en_data)\r\n",
        "dataframe.to_csv(\"sample.csv\", header=False, index=False, mode='w+')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIgdne_i42ZD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0KmeF4t_nNX",
        "outputId": "b266f0fe-02ab-4e02-b6b0-94a05d3fac08"
      },
      "source": [
        "en_data[10:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 'neutral'],\n",
              " [10, 'non-neutral'],\n",
              " [11, 'neutral'],\n",
              " [12, 'sadness'],\n",
              " [13, 'neutral'],\n",
              " [14, 'neutral'],\n",
              " [15, 'neutral'],\n",
              " [16, 'neutral'],\n",
              " [17, 'non-neutral'],\n",
              " [18, 'neutral'],\n",
              " [19, 'neutral'],\n",
              " [20, 'neutral'],\n",
              " [21, 'non-neutral'],\n",
              " [22, 'surprise'],\n",
              " [23, 'non-neutral'],\n",
              " [24, 'joy'],\n",
              " [25, 'non-neutral'],\n",
              " [26, 'anger'],\n",
              " [27, 'neutral'],\n",
              " [28, 'non-neutral']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZUnh1V4JsixM",
        "outputId": "471a424c-1797-4698-93eb-a93f0bd16a7a"
      },
      "source": [
        "sen"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hi pig'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O71rpAxK1zf3",
        "outputId": "b365cd9a-4a8e-4c95-e00b-ed30779e8958"
      },
      "source": [
        "test_data[1:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[  101,   183, 10237,  ...,     0,     0,     0],\n",
              "         [  101, 21852,   102,  ...,     0,     0,     0],\n",
              "         [  101,   102,     0,  ...,     0,     0,     0],\n",
              "         ...,\n",
              "         [  101, 11023, 12257,  ...,     0,     0,     0],\n",
              "         [  101, 17860,   102,  ...,     0,     0,     0],\n",
              "         [  101, 63001, 10718,  ...,     0,     0,     0]]),\n",
              " tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
              "         [1., 1., 1.,  ..., 0., 0., 0.]]),\n",
              " tensor([0, 1, 1, 2, 6, 2, 1, 0, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxhn_WYe21m9",
        "outputId": "a9acac85-cfcb-4387-9b4e-e193172f9682"
      },
      "source": [
        "nltk.download('stopwords')\r\n",
        "import requests\r\n",
        "from pandas import json_normalize\r\n",
        "stops = set(stopwords.words('english'))\r\n",
        "stemmer = nltk.stem.SnowballStemmer('english')\r\n",
        "with open('./friends_test.json') as json_file:\r\n",
        "    json_test = json.load(json_file)\r\n",
        "\r\n",
        "def cleaning(str):\r\n",
        "    replaceAll= str\r\n",
        "    only_english = re.sub('[^a-zA-Z]', ' ', replaceAll)\r\n",
        "    no_capitals = only_english.lower().split()\r\n",
        "    no_stops = [word for word in no_capitals if not word in stops]\r\n",
        "    stemmer_words = [stemmer.stem(word) for word in no_stops]\r\n",
        "    #return ' '.join(stemmer_words)\r\n",
        "    return ' '.join(stemmer_words)\r\n",
        "\r\n",
        "test_data = []\r\n",
        "for rows in json_test:\r\n",
        "    for row in rows:\r\n",
        "        test_data.append([cleaning(row['utterance']), row['emotion']])\r\n",
        "\r\n",
        "en = pd.DataFrame(test_data, columns=['utterance','emotion'])     \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "s2cFmbM87tqH",
        "outputId": "309383d9-4284-4dde-dae3-31155a8b7289"
      },
      "source": [
        "en[10:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>well want</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td></td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>know mayb mean mayb someth wrong</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>oh</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>man seen got</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>hold</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>right man</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>right congratul lucki bastard</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>come lydia</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>push</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>push em push em harder harder</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>push em push em way</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>let get ball realli move hey hey ho ho</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>let yeah right</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>push</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>push</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>okay</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>ross say elev</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>uhh yes okay go</td>\n",
              "      <td>non-neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>okay go left left left</td>\n",
              "      <td>surprise</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 utterance      emotion\n",
              "10                               well want  non-neutral\n",
              "11                                          non-neutral\n",
              "12        know mayb mean mayb someth wrong  non-neutral\n",
              "13                                      oh  non-neutral\n",
              "14                            man seen got          joy\n",
              "15                                    hold  non-neutral\n",
              "16                               right man          joy\n",
              "17           right congratul lucki bastard          joy\n",
              "18                              come lydia      neutral\n",
              "19                                    push          joy\n",
              "20           push em push em harder harder          joy\n",
              "21                     push em push em way          joy\n",
              "22  let get ball realli move hey hey ho ho          joy\n",
              "23                          let yeah right          joy\n",
              "24                                    push          joy\n",
              "25                                    push          joy\n",
              "26                                    okay      neutral\n",
              "27                           ross say elev      neutral\n",
              "28                         uhh yes okay go  non-neutral\n",
              "29                  okay go left left left     surprise"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_VPdc5U1iNO"
      },
      "source": [
        "model.cuda()\r\n",
        "\r\n",
        "def test_sentences(sentences):\r\n",
        "    model.eval()\r\n",
        "    inputs, masks = convert_input_data(sentences)\r\n",
        "\r\n",
        "    b_input_ids = inputs.to(device)\r\n",
        "    b_input_mask = masks.to(device)\r\n",
        "            \r\n",
        "    with torch.no_grad():     \r\n",
        "        outputs = model(b_input_ids, \r\n",
        "                        token_type_ids=None, \r\n",
        "                        attention_mask=b_input_mask)\r\n",
        "        \r\n",
        "    logits = outputs[0]\r\n",
        "    logits = logits.detach().cpu().numpy()\r\n",
        "    return logits\r\n",
        "\r\n",
        "def convert_input_data(sentences):\r\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\r\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\r\n",
        "    attention_masks = []\r\n",
        "\r\n",
        "    for seq in input_ids:\r\n",
        "        seq_mask = [float(i>0) for i in seq]\r\n",
        "        attention_masks.append(seq_mask)\r\n",
        "\r\n",
        "    inputs = torch.tensor(input_ids)\r\n",
        "    masks = torch.tensor(attention_masks)\r\n",
        "\r\n",
        "    return inputs, masks\r\n",
        "\r\n",
        "def inttolabel(idx):\r\n",
        "    return {0:'non-neutral',\r\n",
        "             1:'neutral', \r\n",
        "             2:'joy',\r\n",
        "             3:'sadness',\r\n",
        "             4:'fear',\r\n",
        "             5:'anger',\r\n",
        "             6:'surprise',\r\n",
        "             7:'disgust'}[idx]\r\n",
        "\r\n",
        "en_data = [['Id', 'Predicted']]\r\n",
        "\r\n",
        "for idx in range(len(en['utterance'])):\r\n",
        "  sen = en['utterance'][idx]\r\n",
        "  logit = test_sentences([sen])\r\n",
        "  \r\n",
        "  en_data.append([idx, inttolabel(np.argmax(logit)), en['emotion'][idx]])\r\n",
        "\r\n",
        "dataframe = pd.DataFrame(en_data)\r\n",
        "dataframe.to_csv(\"result.csv\", header=False, index=False, mode='w+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du_c70CnPHZs",
        "outputId": "cbfa2c82-41a8-4da1-f69c-254df7c3ecbc"
      },
      "source": [
        "#logit = test_sentences(['i love it'])\r\n",
        "logit = test_sentences(['i am sad'])\r\n",
        "print(inttolabel(np.argmax(logit)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "non-neutral\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}